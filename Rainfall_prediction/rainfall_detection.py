# -*- coding: utf-8 -*-
"""Rainfall_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LswMzDBIBwskXpIrleEadaACjgM_5qIi
"""

# importing liberies
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Importing Datasets
dataset = pd.read_csv('weatherAUS.csv')
dataset.head()

#Describe Method says the statistics of our data like Maxvalue,Mean,Count..etc for every column
dataset.describe()

#count all the null values in the data
dataset.isna().sum()
dataset['RainToday'] = dataset['RainToday'].replace({'No': 0, 'Yes': 1})
dataset['RainTomorrow'] = dataset['RainTomorrow'].replace({'No': 0, 'Yes': 1})

import pandas as pd
import matplotlib.pyplot as plt

# Replace 'No' and 'Yes' with 0 and 1
dataset['RainToday'] = dataset['RainToday'].replace({'No': 0, 'Yes': 1})
dataset['RainTomorrow'] = dataset['RainTomorrow'].replace({'No': 0, 'Yes': 1})

# Get the columns with string values
string_cols = dataset.select_dtypes(include=['object']).columns

# One-hot encode the string columns
dataset = pd.get_dummies(dataset, columns=string_cols)

# Drop the specified columns


# Calculate missing values
missing_values = dataset.isnull().sum()
print(missing_values)

# Remove columns with many missing values
threshold = 0.5  # Adjust this value based on your requirements
dataset = dataset.loc[:, missing_values / len(dataset) < threshold]

# Calculate the correlation matrix
corr_matrix = dataset.corr()

# Set the figure size
fig, ax = plt.subplots(figsize=(8, 9))

# Generate the heatmap
im = ax.imshow(corr_matrix, cmap='coolwarm')

# Create colorbar
cbar = ax.figure.colorbar(im, ax=ax)
cbar.ax.set_ylabel('Correlation', rotation=-90, va="bottom")

# Set ticks and labels
ax.set_xticks(np.arange(len(corr_matrix.columns)))
ax.set_yticks(np.arange(len(corr_matrix.columns)))
ax.set_xticklabels(corr_matrix.columns, rotation=90)
ax.set_yticklabels(corr_matrix.columns)

# Adjust spacing between labels
plt.subplots_adjust(bottom=0.2, left=0.2)

# Show the plot
plt.show()

"""**cleaning and preprocessing**

Feature Selection

"""

X = dataset.iloc[:,[1,2,3,4,7,8,9,10,11,12,13,14,15,16,19,20,21]].values
Y = dataset.iloc[:,-1].values

print(X)
print(Y)
Y = Y.reshape(-1,1)

"""**Dealing with invalid Data**"""

from sklearn.impute import SimpleImputer
imputer = SimpleImputer(missing_values=np.nan,strategy='most_frequent')
X = imputer.fit_transform(X)
Y = Y.astype(int)
Y = imputer.fit_transform(Y)
print(X)
print(Y)

"""**Encoding Dataset**"""

from sklearn.preprocessing import LabelEncoder
le1 = LabelEncoder()
X[:,0] = le1.fit_transform(X[:,0])
le2 = LabelEncoder()
X[:,4] = le2.fit_transform(X[:,4])
le3 = LabelEncoder()
X[:,6] = le3.fit_transform(X[:,6])
le4 = LabelEncoder()
X[:,7] = le4.fit_transform(X[:,7])
le5 = LabelEncoder()
X[:,-1] = le5.fit_transform(X[:,-1])
le6 = LabelEncoder()
Y[:,-1] = le6.fit_transform(Y[:,-1])



print(X)
Y = np.array(Y,dtype=float)
print(Y)

"""**Feature Scaling**"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X = sc.fit_transform(X)
print(X)
print(Y)

"""MODELLING
**Splitting Dataset into Training set and Test set**
"""

from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=None)
print(X_train)
print(Y_train)
Y_test.shape

"""MODELS

**Training Model**

Random Forest
"""

from sklearn.ensemble import RandomForestClassifier
classifier_rf = RandomForestClassifier(n_estimators=100,random_state=0)
classifier_rf.fit(X_train,Y_train)

classifier_rf.score(X_train,Y_train)

y_pred_rf = le6.inverse_transform(np.array(classifier_rf.predict(X_test),dtype=int))
Y_test_rf = le6.inverse_transform(np.array(Y_test,dtype=int))

print(y_pred_rf)
print("\n\n\n")
print(Y_test_rf)

y_pred_rf = y_pred_rf.reshape(-1,1)
Y_test_rf = Y_test_rf.reshape(-1,1)
df = np.concatenate((Y_test_rf,y_pred_rf),axis=1)
dataframe = pd.DataFrame(df,columns=['Rain on Tommorrow','Predition of Rain'])

print(dataframe)

from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
acc_rfs=accuracy_score(Y_test_rf,y_pred_rf)
acc_rfs

!pip install scikit-learn

!pip install scikit-learn==1.1.3
import sklearn
from sklearn.metrics import confusion_matrix

# Get the confusion matrix
cm = confusion_matrix(Y_test_rf, y_pred_rf)

# Print the confusion matrix
print(cm)

group_names = ['True Pos','False Neg','False Pos','True Neg']
group_counts = ["{0:0.0f}".format(value) for value in
                cm.flatten()]
group_percentages = ['{0:.2%}'.format(value) for value in
                     cm.flatten()/np.sum(cm)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cm, annot=labels, fmt="", cmap='Blues');

print(classification_report(Y_test_rf,y_pred_rf))

"""**Logisitic Regression**"""

from sklearn.linear_model import LogisticRegression
classifier_lr = LogisticRegression(random_state=0)
classifier_lr.fit(X_train, Y_train)

classifier_lr.score(X_train,Y_train)

y_pred_lr = le6.inverse_transform(np.array(classifier_lr.predict(X_test),dtype=int))
Y_test_lr = le6.inverse_transform(np.array(Y_test,dtype=int))

print(y_pred_lr)
print(Y_test_lr)

y_pred_lr = y_pred_lr.reshape(-1,1)
Y_test_lr = Y_test_lr.reshape(-1,1)
df = np.concatenate((Y_test_lr,y_pred_lr),axis=1)
dataframe = pd.DataFrame(df,columns=['Rain on Tommorrow','Predition of Rain'])
print(dataframe)

from sklearn.metrics import accuracy_score
acc_lr=accuracy_score(Y_test_lr,y_pred_lr)
acc_lr

cm_lr=confusion_matrix(Y_test_lr,y_pred_lr)
print(cm_lr)

group_names = ['True Pos','False Neg','False Pos','True Neg']
group_counts = ["{0:0.0f}".format(value) for value in
                cm_lr.flatten()]
group_percentages = ['{0:.2%}'.format(value) for value in
                     cm_lr.flatten()/np.sum(cm_lr)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cm, annot=labels, fmt="", cmap='Reds');

from sklearn.metrics import classification_report
print(classification_report(Y_test_lr,y_pred_lr))

"""**DecisionTree Classifier**"""

from sklearn.tree import DecisionTreeClassifier
classifier_dt = DecisionTreeClassifier(criterion='entropy', random_state=0)
classifier_dt.fit(X_train, Y_train)

classifier_dt.score(X_train,Y_train)
y_pred_dt = le6.inverse_transform(np.array(classifier_dt.predict(X_test),dtype=int))
Y_test_dt = le6.inverse_transform(np.array(Y_test,dtype=int))

classifier_dt.score(X_train,Y_train)

print(y_pred_dt)
print(Y_test_dt)
y_pred_dt = y_pred_dt.reshape(-1,1)
Y_test_dt = Y_test_dt.reshape(-1,1)
df = np.concatenate((Y_test_dt,y_pred_dt),axis=1)
dataframe = pd.DataFrame(df,columns=['Rain on Tommorrow','Predition of Rain'])
print(dataframe)

from sklearn.metrics import accuracy_score
acc_dt=accuracy_score(Y_test_dt,y_pred_dt)
acc_dt

cm_dt=confusion_matrix(Y_test_dt,y_pred_dt)
print(cm_dt)

group_names = ['True Pos','False Neg','False Pos','True Neg']
group_counts = ["{0:0.0f}".format(value) for value in
                cm_dt.flatten()]
group_percentages = ['{0:.2%}'.format(value) for value in
                     cm_dt.flatten()/np.sum(cm_dt)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cm_dt, annot=labels, fmt="", cmap='Purples');

from sklearn.metrics import classification_report
print(classification_report(Y_test_dt,y_pred_dt))

"""**Light Gbm**"""

!pip install lightgbm

from lightgbm import LGBMClassifier
classifier_lgbm = LGBMClassifier(random_state =0)
classifier_lgbm.fit(X_train, Y_train)

classifier_lgbm.score(X_train,Y_train)

y_pred_lgbm = le6.inverse_transform(np.array(classifier_lgbm.predict(X_test),dtype=int))
Y_test_lgbm = le6.inverse_transform(np.array(Y_test,dtype=int))

print(y_pred_lgbm)
print(Y_test_lgbm)

y_pred_lgbm = y_pred_lgbm.reshape(-1,1)
Y_test_lgbm = Y_test_lgbm.reshape(-1,1)
df = np.concatenate((Y_test_lgbm,y_pred_lgbm),axis=1)
dataframe = pd.DataFrame(df,columns=['Rain on Tommorrow','Predition of Rain'])
print(dataframe)

from sklearn.metrics import accuracy_score
acc_lg=accuracy_score(Y_test_lgbm,y_pred_lgbm)
acc_lg

cm_lg=confusion_matrix(Y_test_lgbm,y_pred_lgbm)
print(cm_lg)

group_names = ['True Pos','False Neg','False Pos','True Neg']
group_counts = ["{0:0.0f}".format(value) for value in
                cm_lg.flatten()]
group_percentages = ['{0:.2%}'.format(value) for value in
                     cm_lg.flatten()/np.sum(cm)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cm_lg, annot=labels, fmt="", cmap='Greens');

from sklearn.metrics import classification_report
print(classification_report(Y_test_lgbm,y_pred_lgbm))

"""** xgboost**"""

!pip install xgboost

from xgboost import XGBRegressor
clf_xgb = XGBRegressor(random_state=0)
clf_xgb.fit(X_train,Y_train)

clf_xgb.score(X_train,Y_train)

y_pred_xgb = le6.inverse_transform(np.array(clf_xgb.predict(X_test),dtype=int))
Y_test_xgb = le6.inverse_transform(np.array(Y_test,dtype=int))

print(y_pred_xgb)
print(Y_test_xgb)
y_pred_xgb = y_pred_xgb.reshape(-1,1)
Y_test_xgb = Y_test_xgb.reshape(-1,1)
df = np.concatenate((Y_test_xgb,y_pred_xgb),axis=1)
dataframe = pd.DataFrame(df,columns=['Rain on Tommorrow','Predition of Rain'])
print(dataframe)

from sklearn.metrics import accuracy_score
acc_xgb=accuracy_score(Y_test_xgb,y_pred_xgb)
acc_xgb

cm_xgb=confusion_matrix(Y_test_xgb,y_pred_xgb)
print(cm_xgb)

group_names = ['True Pos','False Neg','False Pos','True Neg']
group_counts = ["{0:0.0f}".format(value) for value in
                cm_xgb.flatten()]
group_percentages = ['{0:.2%}'.format(value) for value in
                     cm_xgb.flatten()/np.sum(cm)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cm_lg, annot=labels, fmt="", cmap='Greens');

from sklearn.metrics import classification_report
print(classification_report(Y_test_xgb,y_pred_xgb))

"""**Accuracy Comparison**"""

accuracy_dict = {"Logistic Regression": acc_lr,
                 "Random Forest": acc_rfs,
                 "Decision Trees": acc_dt,
                 "LightGBM": acc_lg,
                 "Xgboost": acc_xgb}

accuracy_df = pd.DataFrame( pd.Series(accuracy_dict, index = accuracy_dict.keys()), columns = ["Accuracy"])
accuracy_df

fig = plt.gcf();
fig.set_size_inches(12, 8);

sns.lineplot(x = accuracy_df.index, y = accuracy_df.Accuracy*100);
sns.barplot(x = accuracy_df.index, y = accuracy_df.Accuracy*100);

for i, val in enumerate(accuracy_df.index):
    y = round(accuracy_df.loc[val].sum()*100, 3)
    plt.text(i, y-5, str(y), ha = "center")

import pickle
filename = 'trained_model.sav'
pickle.dump(classifier_rf,open(filename,'wb'))
loaded_model=pickle.load(open('trained_model.sav','rb'))

!pip install streamlit
import numpy as np
import pickle
import streamlit as st
from sklearn.preprocessing import StandardScaler

!pip install streamlit --quiet
!pip install pyngrok

!pip install ipykernel

import streamlit as st

loaded_model=pickle.load(open('/content/trained_model.sav','rb'))

#creating a function for prediction

def rainfall_predict(input_data):
    input_data=np.asarray(input_data)
    input_data=input_data.reshape(1,-1)
    #sc1 = StandardScaler()
    #input_data = sc1.fit_transform(input_data)

    y_pred = (np.array(loaded_model.predict(input_data),dtype=int))
    if(y_pred[0]==0):
        return 'Tomorrow there will be rainfall'
    else:
        return 'Tomorrow there is no rainfall'




def main():

    #Giving a title
    print('Rainfall Prediction Web App')

    area=['Albury', 'BadgerysCreek' ,'Cobar', 'CoffsHarbour', 'Moree' ,'Newcastle',
 'NorahHead' ,'NorfolkIsland' ,'Penrith' ,'Richmond' ,'Sydney', 'SydneyAirport',
 'WaggaWagga' ,'Williamtown' ,'Wollongong', 'Canberra' ,'Tuggeranong',
 'MountGinini', 'Ballarat', 'Bendigo', 'Sale' ,'MelbourneAirport' ,'Melbourne',
 'Mildura' ,'Nhil' ,'Portland', 'Watsonia', 'Dartmoor' ,'Brisbane' ,'Cairns',
 'GoldCoast' ,'Townsville' ,'Adelaide', 'MountGambier', 'Nuriootpa' ,'Woomera',
 'Albany', 'Witchcliffe' ,'PearceRAAF' ,'PerthAirport' ,'Perth' ,'SalmonGums',
 'Walpole' ,'Hobart' ,'Launceston' ,'AliceSprings' ,'Darwin' ,'Katherine',
 'Uluru']

    direction=['nan','W', 'WNW' ,'WSW', 'NE' ,'NNW', 'N' ,'NNE', 'SW','ENE' ,'SSE', 'S',
               'NW' ,'SE','ESE', 'E' ,'SSW']
   # #Location=st.selectbox('Select a location',options=area)
    #MinTemp=input('Enter minimum temperature of the day in celcius')
    #MaxTemp=input('Enter maximum temperature of the day in celcius')
    #Rainfall=input('Enter rainfall in cms')
    #WindGustDir=st.selectbox('Select wind gust direction ',options=direction)
    #WindGustSpeed=input('Enter the gust speed in meter/sec')
    #WindDir9am=st.selectbox('Select wind direction at 9am',options=direction)
    #WindDir3pm=st.selectbox('Select wind direction at 3pm',options=direction)
    #WindSpeed9am=input('Enter wind speed at 9am in m/sec')
    #WindSpeed3pm=input('Enter wind speed at 3pm in m/sec')
    #Humidity9am=input('Enter humidity at 9am in gm/kg')
    #Humidity3pm=input('Enter humidity at 3pm in gm/kg')
    #Pressure9am=input('Enter pressure at 9am in atm')
    #Pressure3pm=input('Enter pressure at 3pm in atm')
    #Temp9am=input('Enter the temperature at 9am in celcius')
    #Temp3pm=input('Enter the temperature at 3pm in celcuis')
    #RainToday=st.text_input('Enter rain today,if yes 1 else 0')"""

    #code for prediction

    diagonsis=''
    diagonsis=rainfall_predict(['Albury',13.4,22.9,0.6,'W',44,'W','WNW',20,24,71,22,1007.7,1007.1,16.9,21.8,0])

    print()
    print(diagonsis)

if __name__ =='__main__':
    main()

import streamlit as st
import pickle
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier

loaded_model = pickle.load(open('/content/trained_model.sav', 'rb'))

# Creating a function for prediction
def rainfall_predict(input_data):
    input_data_encoded = []
    categorical_indices = [0, 4, 6, 7]  # Indices of categorical features
    label_encoders = [LabelEncoder() for _ in categorical_indices]

    # Perform label encoding for categorical features
    for i, value in enumerate(input_data):
        if i in categorical_indices:
          label_encoders[categorical_indices.index(i)].fit(['nan'] + [value])
          input_data_encoded.append(label_encoders[categorical_indices.index(i)].transform([value])[0])
        else:
            input_data_encoded.append(value)

    input_data_encoded = np.asarray(input_data_encoded)
    input_data_encoded = input_data_encoded.reshape(1, -1)

    y_pred = np.array(loaded_model.predict(input_data_encoded), dtype=int)
    if y_pred[0] == 1:
        return 'Tomorrow there will be rainfall'
    else:
        return 'Tomorrow there is no rainfall'


def main():
    # Giving a title
    print('Rainfall Prediction Web App')

    area = ['Albury', 'BadgerysCreek', 'Cobar', 'CoffsHarbour', 'Moree', 'Newcastle',
            'NorahHead', 'NorfolkIsland', 'Penrith', 'Richmond', 'Sydney', 'SydneyAirport',
            'WaggaWagga', 'Williamtown', 'Wollongong', 'Canberra', 'Tuggeranong',
            'MountGinini', 'Ballarat', 'Bendigo', 'Sale', 'MelbourneAirport', 'Melbourne',
            'Mildura', 'Nhil', 'Portland', 'Watsonia', 'Dartmoor', 'Brisbane', 'Cairns',
            'GoldCoast', 'Townsville', 'Adelaide', 'MountGambier', 'Nuriootpa', 'Woomera',
            'Albany', 'Witchcliffe', 'PearceRAAF', 'PerthAirport', 'Perth', 'SalmonGums',
            'Walpole', 'Hobart', 'Launceston', 'AliceSprings', 'Darwin', 'Katherine',
            'Uluru']

    direction = ['nan', 'W', 'WNW', 'WSW', 'NE', 'NNW', 'N', 'NNE', 'SW', 'ENE', 'SSE', 'S',
                 'NW', 'SE', 'ESE', 'E', 'SSW']

    # code for prediction
    diagonsis = rainfall_predict(['CoffsHarbour', 9.7, 31.9, 0, 'NNW', 80, 'SE', 'NW', 7, 28, 42, 9, 1008.9, 1003.6, 18.3,
                                  30.2, 1])

    print()
    print(diagonsis)


if __name__ == '__main__':
    main()